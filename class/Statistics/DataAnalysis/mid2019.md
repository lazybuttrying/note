3. Scale의 4가지 수준?
- Nominal Scale
  - 정의: 데이터의 범주
  - ex) 성별[M,F], 혈액형[A,B,O,AB], 국가 이름 등
- Ordinal Scale
  - 정의: 데이터의 순서
  - ex) 만족도 조사 [불만족, 보통 만족], 등급
- Interval Scale
  - 정의: 데이터 간 차이 "일정" + 0점을 "임의로" 설정으로 비율 비교 불가능
  - ex) 온도[C,F], 날짜[연도] 등
- Ratio Scale
  - 정의: 데이터 간 차이 "일정" + "절대적인" 0점 존재로 비율 비교 가능
  - ex) 길이[m, cm], 무게, 시간 등
  



---


4. 확률에 대한 공리(axiom)?
- $\forall A$, $P(A) \geq 0$
- for sample space $S$, $P(S)=1$
- for two events $A_1$ and $A_2$, $P(A_1 \cup A_2)= P(A_1) + P(A_2) -P(A_1 \cap A_2)$

---

5. 확률의 정의?
- 고전적 확률: P(A)=\cfrac{n(A)}{n(S)}
  - Probability of A = ratio of "num of elementary events in event A" and "num of elementary events of Sample space"

---

6. $P_A = P(sex=M)=0.5$, $$P_B = P(university=Accept)=0.2$
- if independent: $P(A\cap B) = 0.5 \cdot 0.2=0.1$
- if mutually exclusive: $P(A \cap B) = 0$


---

7. OLS vs MLE


- 추정의 원리:
  - OLS: $\min \Sigma(y_i - \hat{y_i})^2$
    - 데이터와의 거리(잔차)의 제곱을 최소화하여 추정값을 도출
  - MLE: $\max \log P(X|\theta)$
    - $\theta$는 추정할 모수(예로 평균)
    - 데이터가 관찰될 확률을 최대화하여 파라미터를 추정
- 평균에 대하여 "정규분포"를 따르는 경우, OLS와 MLE는 동일한 추정량을 산출함. But 분포가 달라지든지 or 추정하고자 하는 parameter가 달라지면 두 방법이 산출하는 추정량은 동일하지 않은 것이 일반적이다.
  - $f(x) = \cfrac{1}{\sqrt{2\pi}\sigma} \cdot e^{\cfrac{-(x-\mu)^2}{2\sigma^2}}$에서 
  - $L = (\cfrac{1}{\sqrt{2\pi}\sigma})^n \cdot e^{\cfrac{\Sigma -(x_i-\mu)^2}{2\sigma^2}}$
    - $\mu$에 뭘 넣어야 최대가 될까?
  
  


---

8. 베이즈 정리 설명. 언제 사용되는가?


- 설명: 베이즈 정리(Bayes' Theorem)는 조건부 확률을 이용하여 어떤 사건의 확률을 업데이트하는 방법을 제공하는 수학적 공식입니다. 이는 새로운 증거가 주어졌을 때, 기존의 믿음을 수정하는 데 사용됩니다. 
$P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}$
    - $P(A | B)$: 사건 $B$가 주어졌을 때 사건 $A$의 조건부 확률
    - $P(B | A)$: 사건 $A$가 주어졌을 때 사건 $B$의 조건부 확률
    - $P(A)$: 사건 $A$의 사전 확률 (prior probability)
    - $P(B)$: 사건 $B$의 전체 확률

- 사용 예시

1. **의료 진단**:
   - 특정 질병에 대한 테스트 결과가 양성일 때, 환자가 실제로 그 질병에 걸렸을 확률을 계산하는 데 사용됩니다. 여기서 $A$는 환자가 질병에 걸렸다는 사건, $B$는 테스트 결과가 양성이라는 사건입니다.

2. **스팸 필터링**:
   - 이메일이 스팸인지 아닌지를 판별할 때, 과거의 스팸 이메일 데이터를 기반으로 특정 단어가 포함되어 있을 때 스팸일 확률을 계산하는 데 사용됩니다.

---

9. 확률밀도함수 확률질량함수 설명 & 언제 사용하는지



- 확률 질량 함수 (PMF)
  - 정의
    - 이산형 확률 변수의 ***각 값에 대해 해당 값이 발생할 확률***을 나타내는 함수
    - PMF는 각 가능한 값에 대한 확률을 제공
  - 특징
    - PMF의 값은 0 이상
    - 모든 가능한 값의 확률의 합은 1: $\sum_{x} P(X = x) = 1$
    - 각 값 $x$에 대해 $P(X = x)$는 확률
  - 예시
   - 주사위 던지기, 동전 던지기, 특정 사건의 발생 횟수 등


- 확률 밀도 함수 (PDF)
  - 정의
    - 연속형 확률 변수가 ***특정 값 주위에서 얼마나 밀집되어 있는지*** 를 나타내는 함수
    - 특정 구간에 대한 면적 = 해당 구간 내의 확률
  - 특징:
    - PDF의 값은 항상 0 이상
    - 전체 확률은 1이 되도록 정규화: $\int_{-\infty}^{\infty} f(x) \, dx = 1$
    - 특정 구간 [a, b]에서의 확률 = 
    $P(a < X < b) = \int_{a}^{b} f(x) \, dx$
  - 예시
    - 정규분포, 지수분포 등과 같은 연속형 확률 변수

---

10. 정규분포

$f(x) = \cfrac{1}{\sqrt{2\pi}\sigma} \cdot e^{\cfrac{-(x-\mu)^2}{2\sigma^2}}$

---

11. 수식 완성 (X와 Y는 correlated)
- $E(aX+bY+c) = aE(X)+bE(Y)+c$
- $Var(aX+bY) = a^2Var(X) + b^2Var(Y) + 2abCov(X,Y)$


- $Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E(XY)-E(X)E(Y)$
- $Var(X+c) = Var(X)$
- $Var(X-Y) = Var(X) + Var(Y)$
- $Cov(X,X) = Var(X)$
- $Corr(x,y)=\cfrac{Cov(x,y)}{SD(x)\cdot SD(y)}= \Sigma \frac{z_{x_i}z_{y_i}}{n}$
- $Cov(X,Y)=Corr(X,Y)\cdot (SD_x \cdot SD_y)$
---

+) 상관계수에 영향을 미치는 요인들
- 극단값: outlier
- 분리된 집단: subgroup -> Simpson's Paradox
- 범위의 제한
- 비연속적인 분포: non-linear

---

12. 중심극한정리

- 원래 모집단의 분포에 관계없이 $\bar{X}$의 분포는 표본크기(N)이 커짐에 따라 정규분포에 접근
- 이 때 평균은 $\mu$, 분산은 $\sigma^2/N$


---


13. ? = 10의 의미 없는 진술이다 왜?

- ?: IQ=100일 확률이 가장 높지만 100일 때의 확륭느 구할 수 없다. PDF라서 확률은 점이 아닌 면적이기에?
- 고로 $P(X=?)=0$ and $P(c<x<d)=P(c\leq x \leq d)$

---


14. 해석: 제품의 불량률의 신뢰구간이 [0.01, 0.03]
- 불량 제품이 나올 확률은 0.01 ~ 0.03 사이가 높다


---


15. 어떤 통계량이 Chi-square분포와 F분포를 따르는지 설명하라. 이 두 분포의 parameter에 대하여 기술하라
- $\chi^2$ distribution: 분산
  - 표본 분산을 모수(모집단의 분산)로 나눈 비율
  - 독립적인 정규분포를 따르는 확률변수의 제곱합
    - $X_1, X_2, \dots, X_n$이 표준정규분포를 따를 때,
    - $\sum_{i=1}^{n} X_i^2$은 Chi-square 분포를 따릅니다.
  - parameter: 자유도 $df(k)$
- $F$ distribution: 2개의 $\chi^2$ 분포 간 비율
  - 두 모집단의 분산 비율 비교 시 -> ANOVA
  - 회귀분석에서 모델의 유의성 검정 시의 F statistics
  - parameter: 자유도 2개 from $\chi^2$ distribution


---


16. 어떤 가설검증에서 p=.000001인데, 검증력=.01인 결과를 얻었다. 이에 대해 어떤 해석을 할 수 있는가?
- p-value가 일반적인 유의수준($\alpha=0.05$)보다 매우 낮으므로 Reject $H_0$
- $power=0.01$: 연구자가 대립가설을 올바르게 기각할 확률이 1%. 즉 true $H_1$을 올바르게 검정할 가능성이 매우 낮다
  - 연구 설계 or 표본 크기가 적절하지 않음을 시사함
- 결론: p-value is enough to reject $H_0$, but power is too low to trust. More research and sample size are needed.


---

+) Power Analysis
- Power up에 영향을 주는 요인
  - effect size up
  - sample size up
  - alpha level up
- 위 4개 중 3개를 알면 나머지 하나는 계산 가능

---

17. 효과의 크기 (effect size), 표본크기(N), 검증비(power)의 관계
- 의미
  - effect size: 특정 처치나 요인이 결과에 미치는 영향을 정량화. large effect size means valuable research.
    - $d=\frac{\mu_1-\mu_2}{\sigma}$
  - sample size: large sample size increases confidence by decreasing standard error
  - power(over 80%): probability to reject rightly when $H_1=true$ 
- 관계
  - Increase effect size($|\mu_0-\mu_1|$) -> Increase Power ($1-\beta$) -> Decrease Type II Error![](https://wikidocs.net/images/page/163986/error05.png)
  - increase sample size -> lower error -> power up
    - t-value 공식을 생각해보면 별거 아님
    - sample size is controllable
  - increase alpha -> power up


---

18. 교육방법 A, B 각각 100명으로 구성.
- 주어진 정보
  - $\bar{X}_A=25$, $s^2_A=2^2$, $\bar{X}_B=20$, $s^2_B=4^2$
- 즉, 우리는 모집단의 표준편차를 모른다
  - 그러므로 표본의 표준편차를 사용하여 모집단의 표준편차를 추정할 수밖에 없다
  - $Z=\cfrac{\bar{X}-\mu_X}{\sigma_X}$에서 $\sigma$를 수정하면,
  - $t=\cfrac{\bar{X}-\mu_{\bar{X}}}{s_{\bar{X}}}$는 더 이상 정규분포를 따르지 않고, t분포를 따르므로 t분포를 사용하여 p-value를 계산하여야 한다
    - Variance $= \cfrac{df}
    {df-2}$
    - $t=\cfrac{Z}{\sqrt{V/df}} \thicksim t(df)$
      - $Z \thicksim Normal$, $V \thicksim \chi^2$




- (1) A 교육 방법이 B 교육 방법보다 평균적으로 더 교육 효과가 크다는 가설 검정
  - 평균에 대하여 크다라는 비교에 대해서 검증하므로 One-tailed test
    - $H_0: \mu_A \leq \mu_B$
    - $H_1: \mu_A > \mu_B$
    - p-value:



    - t-value: $t = \cfrac{\bar{X_A}-\bar{X_B}}{\sqrt{\cfrac{S_A^2}{n_A}+\cfrac{S_B^2}{n_B}}}=11.18$
  - p-value
    - $df = 100+100-2=198$
    
    
  ????

  - Type 2 Error

- (2) A 교육 방법의 효과가 B 교육 방법의 효과보다 학생들에게 더 균등하게 작용한다는 가설 검정
  - 가설검증은 영가설 기각 여부만 논할 뿐. t-test라면 두 평균의 차이 여부만 볼 뿐, 그 차이가 얼마나 큰 지, 다시 연구를 하면 반복 검증이 가능한지 등에 대한 정보는 제공하지 않음. 이럴 때는 effect size와 power
  - 평균의 차이에 대한 effect size $d=\cfrac{|\mu_1-\mu_2|}{\sigma}$
  - 이 때의 estimator of $\sigma$는 $\hat{\sigma} = \sqrt{\cfrac{s_1^2+s_2^2}{2}}$










 